# 视频链接 # 
https://www.bilibili.com/video/BV1QA4m1F7t4/
# 教程文档 #
https://github.com/InternLM/Tutorial/blob/camp2/huixiangdou/readme.md

# 笔记
茴香豆技术报告：https://arxiv.org/abs/2401.08772
本文主要介绍了一种名为"HuixiangDou"的技术助手，它是一个泛学术类文献阅读助手。文章首先介绍了该助手的三个部分：预处理、拒绝和回应，并详细描述了它们的功能。接着，文章讨论了助手对于不同类型问题的回答能力，并提供了一些示例。然后，文章介绍了助手的一些技术实现和验证，包括LLM的Fine-tuning过程、拒绝流程的效果、评分方法的实施和测试、长上下文回应的必要实验以及搜索能力的增强尝试。最后，文章提出了一些助手的局限性和未来的改进方向。

### 群聊的技术助手特点：
- True help-seekers： 只回答技术相关问题，不闲聊
- Strictly no hallucination： 真实可靠，不能有幻觉
- Understand domain-specific knowledge：知道领域知识，并且可以以相对地成本的方式更新知识库
- No rush for response：不需要太及时的相应 # 个人对这点存疑

## 主要方法
这篇论文介绍的主要实现方法包括以下几个方面：

1. **预处理用户输入**：将多个连续的消息整合为一个单一消息，同时使用OCR服务解析图像，并忽略其他元素如视频、表情符号和语音消息。

2. **拒绝管道**：基于LLM评分和text2vec模型来判断是否回应用户的问题。这样做的目的是避免模型产生虚幻的回应。

3. **响应管道**：利用LLM的NLP部分词分割任务优势来从查询中提取关键字和短语。首先从多个搜索结果中提取数据（根据模型支持的最大token长度），然后使用LLM评分过滤与问题相关的结果。最后将这些结果打包成背景文档。

4. **特征和重排**：通过混合使用LangChain和BCEmbedding来检索特定领域的知识。为了节省成本，论文中提到了一种混合调度不同LLM的方法。此外，论文还建立了一套安全机制，以确保对话组回复不涉及敏感主题。

5. **安全**：通过LLM评分检查所有字符串变量及其与禁止主题的关联，以避免生成非法内容。同时，设置助手的工作时间，以确保所有活动都在人类监督下进行。

这些方法共同构成了一个全面的技术助手解决方案，可以在群聊场景中有效地帮助用户解答问题。

![image](https://github.com/noirblack/InternLM2/assets/9305115/3ac3752d-7899-43a5-aa30-bcbbfa35c437)



